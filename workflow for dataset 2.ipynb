{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML workflow for  banknote authentication Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "from pipeline_perso import *  # this is our utilities .py file implemented by the members of our group . \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_banknote_authentication.txt',header=None)\n",
    "data.columns=['variance','skewness','curtosis','entropy','classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  classification\n",
       "0   3.62160    8.6661   -2.8073 -0.44699               0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210               0\n",
       "2   3.86600   -2.6383    1.9242  0.10645               0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440               0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTest=TrainTestGenerator(1,test_size=0.3,data=data)\n",
    "for train,test in TrainTest:\n",
    "    X_train = np.array(data.drop(['classification'],axis=1))[train]\n",
    "    X_test  = np.array(data.drop(['classification'],axis=1))[test]\n",
    "    y_train = np.array(data.classification)[train]\n",
    "    y_test  = np.array(data.classification)[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch with CV for several models and retrain the best model  and evaluate on test set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score for model : LogisticRegression is 0.9830097087378641\n",
      "best parameters for model : LogisticRegression are {'C': 25}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       224\n",
      "           1       0.99      0.97      0.98       188\n",
      "\n",
      "    accuracy                           0.98       412\n",
      "   macro avg       0.98      0.98      0.98       412\n",
      "weighted avg       0.98      0.98      0.98       412\n",
      "\n",
      "accuracy score for model : SVM is 1.0\n",
      "best parameters for model : SVM are {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       224\n",
      "           1       1.00      1.00      1.00       188\n",
      "\n",
      "    accuracy                           1.00       412\n",
      "   macro avg       1.00      1.00      1.00       412\n",
      "weighted avg       1.00      1.00      1.00       412\n",
      "\n",
      "accuracy score for model : KNN is 1.0\n",
      "best parameters for model : KNN are {'n_neighbors': 4, 'leaf_size': 1, 'weights': 'uniform', 'n_jobs': -1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       224\n",
      "           1       1.00      1.00      1.00       188\n",
      "\n",
      "    accuracy                           1.00       412\n",
      "   macro avg       1.00      1.00      1.00       412\n",
      "weighted avg       1.00      1.00      1.00       412\n",
      "\n",
      "accuracy score for model : DecisionTree is 0.9854368932038835\n",
      "best parameters for model : DecisionTree are {'min_samples_split': 10, 'max_depth': 7, 'criterion': 'entropy'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       224\n",
      "           1       0.99      0.97      0.98       188\n",
      "\n",
      "    accuracy                           0.99       412\n",
      "   macro avg       0.99      0.98      0.99       412\n",
      "weighted avg       0.99      0.99      0.99       412\n",
      "\n",
      "accuracy score for model : RandomForestClassifier is 0.9927184466019418\n",
      "best parameters for model : RandomForestClassifier are {'n_estimators': 500, 'max_features': 'log2', 'max_depth': 8, 'criterion': 'gini'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       224\n",
      "           1       1.00      0.98      0.99       188\n",
      "\n",
      "    accuracy                           0.99       412\n",
      "   macro avg       0.99      0.99      0.99       412\n",
      "weighted avg       0.99      0.99      0.99       412\n",
      "\n",
      "accuracy score for model : CATBOOST is 0.9951456310679612\n",
      "best parameters for model : CATBOOST are {'depth': 6, 'learning_rate': 0.1, 'iterations': 100, 'silent': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       224\n",
      "           1       1.00      0.99      0.99       188\n",
      "\n",
      "    accuracy                           1.00       412\n",
      "   macro avg       1.00      0.99      1.00       412\n",
      "weighted avg       1.00      1.00      1.00       412\n",
      "\n",
      "#############################################################################\n",
      "BEST MODEL : \n",
      "accuracy score for model : SVM is 1.0\n",
      "best parameters for model : SVM are {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       224\n",
      "           1       1.00      1.00      1.00       188\n",
      "\n",
      "    accuracy                           1.00       412\n",
      "   macro avg       1.00      1.00      1.00       412\n",
      "weighted avg       1.00      1.00      1.00       412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model,best_model_name,best_param,best_score=train_get_best_model(X_train,y_train,X_test,y_test,metric='accuracy',verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
